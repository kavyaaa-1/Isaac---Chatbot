{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in c:\\users\\gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.2.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: pydub in c:\\users\\gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.25.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def audio_start():\n",
    "    \n",
    "    r = sr.Recognizer()\n",
    "\n",
    "    with sr.Microphone() as source:\n",
    "        # read the audio data from the default microphone \n",
    "        r.adjust_for_ambient_noise(source)\n",
    "\n",
    "        audio_data = r.record(source, duration=5)\n",
    "        print(\"Recognizing...\")\n",
    "        \n",
    "        try:\n",
    "        # convert speech to text\n",
    "            text = r.recognize_google(audio_data)\n",
    "            print(\"You: \" + text)\n",
    "        except Exception:\n",
    "            print(\"No Speech or No Internet\")\n",
    "            audio_start()\n",
    "            \n",
    "        if \"are you ready to learn\" in text:\n",
    "            \n",
    "            print(\"Isaac: Yes! I am listening.\")\n",
    "        \n",
    "            r.pause_threshold = 5\n",
    "            audio = r.record(source, duration = 30)\n",
    "            print(\"Recognizing...\")\n",
    "\n",
    "            \n",
    "            try:\n",
    "                audio_data = r.recognize_google(audio)\n",
    "                \n",
    "            except Exception:\n",
    "                print(\"No Speech or No Internet\")\n",
    "                \n",
    "            \n",
    "    return audio_data       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: tflearn in c:\\users\\gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tflearn) (1.22.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tflearn) (9.1.1)\n",
      "Requirement already satisfied: six in c:\\users\\gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tflearn) (1.16.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\gupta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import tflearn\n",
    "import string\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer =  LancasterStemmer()\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (2022.6.2)\n",
      "Requirement already satisfied: click in c:\\users\\gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gupta\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6999  | time: 0.042s\n",
      "| Adam | epoch: 500 | loss: 0.00000 - acc: 0.9987 -- iter: 104/108\n",
      "Training Step: 7000  | time: 0.046s\n",
      "| Adam | epoch: 500 | loss: 0.00000 - acc: 0.9988 -- iter: 108/108\n",
      "--\n",
      "INFO:tensorflow:c:\\Users\\gupta\\basic\\Chatbot\\model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:c:\\Users\\gupta\\basic\\Chatbot\\model.tflearn.data-00000-of-00001\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:c:\\Users\\gupta\\basic\\Chatbot\\model.tflearn.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:c:\\Users\\gupta\\basic\\Chatbot\\model.tflearn.meta\n",
      "INFO:tensorflow:200\n"
     ]
    }
   ],
   "source": [
    "with open (\"isaac_dataset.json\") as file:\n",
    "  data=json.load(file)\n",
    "try:\n",
    "  with open(\"data.pickle\",\"rb\") as f:\n",
    "    words,labels,training,output=pickle.load(f)\n",
    "except:\n",
    "  words=[]\n",
    "  labels=[]\n",
    "  docs_x=[]\n",
    "  docs_y=[]\n",
    "\n",
    "  for intent in data[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "      wrds=nltk.word_tokenize(pattern)\n",
    "      words.extend(wrds)\n",
    "      docs_x.append(wrds)\n",
    "      docs_y.append(intent[\"tag\"])\n",
    "\n",
    "    if intent[\"tag\"] not in labels:\n",
    "      labels.append(intent[\"tag\"])\n",
    "\n",
    "  words=[stemmer.stem(w.lower()) for w in words if w not in \"?\"]\n",
    "  words=sorted(list(set(words)))\n",
    "  labels=sorted(labels)\n",
    "  training=[]\n",
    "  output=[]\n",
    "  out_empty=[0 for _ in range(len(labels))]\n",
    "\n",
    "  for x,doc in enumerate(docs_x):\n",
    "    bag=[]\n",
    "\n",
    "    wrds=[stemmer.stem(w.lower()) for w in doc]\n",
    "    for w in words:\n",
    "      if w in wrds:\n",
    "        bag.append(1)\n",
    "      else:\n",
    "        bag.append(0)\n",
    "\n",
    "    output_row=out_empty[:]\n",
    "    output_row[labels.index(docs_y[x])]=1\n",
    "\n",
    "    training.append(bag)\n",
    "    output.append(output_row)\n",
    "\n",
    "  training=np.array(training)\n",
    "  output=np.array(output)\n",
    "\n",
    "  with open(\"data.picle\",\"wb\") as f:\n",
    "    pickle.dump((words,labels,training,output),f)\n",
    "\n",
    "ops.reset_default_graph()\n",
    "\n",
    "net=tflearn.input_data(shape=[None,len(training[0])])\n",
    "net=tflearn.fully_connected(net,8)\n",
    "net=tflearn.fully_connected(net,8)\n",
    "net=tflearn.fully_connected(net,len(output[0]),activation='softmax')\n",
    "net=tflearn.regression(net)\n",
    "\n",
    "model=tflearn.DNN(net)\n",
    "try:\n",
    "  model.load(\"model.tflearn\")\n",
    "except:\n",
    "  model=tflearn.DNN(net)\n",
    "  model.fit(training,output,n_epoch=500,batch_size=8,show_metric=True)\n",
    "  model.save(\"model.tflearn\")\n",
    "\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(s,words):\n",
    "  bag=[0 for _ in range(len(words))]\n",
    "  s_words=nltk.word_tokenize(s)\n",
    "  s_words=[stemmer.stem(word.lower())for word in s_words]\n",
    "  for se in s_words:\n",
    "    for i,w in enumerate(words):\n",
    "      if w==se:\n",
    "        bag[i] = 1\n",
    "  return np.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "  \n",
    "  print(\"Isaac: Heyy\")\n",
    "  inp = audio_start()\n",
    "  print(\"You: \" + inp)\n",
    "\n",
    "  results=model.predict([bag_of_words(inp,words)])\n",
    "  results_index=np.argmax(results)\n",
    "  tag=labels[results_index]\n",
    "\n",
    "  for tg in data[\"intents\"]:\n",
    "    if tg[\"tag\"]==tag:\n",
    "      response=tg['responses']\n",
    "      print(tag)\n",
    "\n",
    "  corpus_text = listToString(response)\n",
    "  print(\"Issac: \"+ (answer(corpus_text,inp)))\n",
    "  \n",
    "  return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToString(response):\n",
    "   \n",
    "    str1 = \" \"\n",
    "    return (str1.join(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(corpus_text,inp):\n",
    "  corpus_sentences=nltk.sent_tokenize(corpus_text)\n",
    "  corpus_words=nltk.word_tokenize(corpus_text)\n",
    "\n",
    "  wn_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "  def lemmatize_data(tokens):\n",
    "    return [wn_lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "  punct_remover=dict((ord(punctuation),None) for punctuation in string.punctuation)\n",
    "\n",
    "  def get_processed_data(data):\n",
    "    return lemmatize_data(nltk.word_tokenize(data.lower().translate(punct_remover)))\n",
    "\n",
    "  corpus_sentences.append(inp)\n",
    "\n",
    "  word_vectorizer=TfidfVectorizer(tokenizer=get_processed_data)\n",
    "  corpus_word_vectors=word_vectorizer.fit_transform(corpus_sentences)\n",
    "  cos_sin_vectors=cosine_similarity(corpus_word_vectors[-1],corpus_word_vectors)\n",
    "  similar_response_idx=cos_sin_vectors.argsort()[0][-2]\n",
    "\n",
    "  return corpus_sentences[similar_response_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_ques():\n",
    "    tag = chat()\n",
    "    r2 = sr.Recognizer()\n",
    "    text2 = \"\"\n",
    "\n",
    "    with sr.Microphone() as source:\n",
    "        # read the audio data from the default microphone\n",
    "        r2.adjust_for_ambient_noise(source)\n",
    "\n",
    "        audio_data2 = r2.record(source, duration = 20)\n",
    "        print(\"Recognizing...\")\n",
    "                    \n",
    "        try:\n",
    "            # convert speech to text\n",
    "            text2 += r2.recognize_google(audio_data2)\n",
    "            print(\"You: \" + text2)\n",
    "        except Exception:\n",
    "            print(\"No Speech or No Internet\")\n",
    "            \n",
    "\n",
    "    for tg in data[\"intents\"]:\n",
    "        if tg[\"tag\"] == tag:\n",
    "            if text2 in tg[\"patterns\"]:\n",
    "                print(\"Yess, Good Job !\")\n",
    "            else:\n",
    "                print(\"No, that's the wrong answer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isaac: Heyy\n",
      "Recognizing...\n",
      "You: hey Isaac are you ready to learn\n",
      "Isaac: Yes! I am listening.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gupta\\basic\\Chatbot\\issac.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gupta/basic/Chatbot/issac.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ask_ques()\n",
      "\u001b[1;32mc:\\Users\\gupta\\basic\\Chatbot\\issac.ipynb Cell 15\u001b[0m in \u001b[0;36mask_ques\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gupta/basic/Chatbot/issac.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mask_ques\u001b[39m():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gupta/basic/Chatbot/issac.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     tag \u001b[39m=\u001b[39m chat()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gupta/basic/Chatbot/issac.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     r2 \u001b[39m=\u001b[39m sr\u001b[39m.\u001b[39mRecognizer()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gupta/basic/Chatbot/issac.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     text2 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32mc:\\Users\\gupta\\basic\\Chatbot\\issac.ipynb Cell 15\u001b[0m in \u001b[0;36mchat\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gupta/basic/Chatbot/issac.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mchat\u001b[39m():\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gupta/basic/Chatbot/issac.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mIsaac: Heyy\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gupta/basic/Chatbot/issac.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   inp \u001b[39m=\u001b[39m audio_start()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gupta/basic/Chatbot/issac.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mYou: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m inp)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gupta/basic/Chatbot/issac.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   results\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mpredict([bag_of_words(inp,words)])\n",
      "\u001b[1;32mc:\\Users\\gupta\\basic\\Chatbot\\issac.ipynb Cell 15\u001b[0m in \u001b[0;36maudio_start\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gupta/basic/Chatbot/issac.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mIsaac: Yes! I am listening.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gupta/basic/Chatbot/issac.ipynb#X20sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m r\u001b[39m.\u001b[39mpause_threshold \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gupta/basic/Chatbot/issac.ipynb#X20sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m audio \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39;49mrecord(source, duration \u001b[39m=\u001b[39;49m \u001b[39m30\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gupta/basic/Chatbot/issac.ipynb#X20sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRecognizing...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gupta/basic/Chatbot/issac.ipynb#X20sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\gupta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\speech_recognition\\__init__.py:497\u001b[0m, in \u001b[0;36mRecognizer.record\u001b[1;34m(self, source, duration, offset)\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[39mif\u001b[39;00m offset_time \u001b[39m>\u001b[39m offset:\n\u001b[0;32m    495\u001b[0m         offset_reached \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m buffer \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mread(source\u001b[39m.\u001b[39;49mCHUNK)\n\u001b[0;32m    498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buffer) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[39mif\u001b[39;00m offset_reached \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m offset:\n",
      "File \u001b[1;32mc:\\Users\\gupta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\speech_recognition\\__init__.py:161\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, size):\n\u001b[1;32m--> 161\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpyaudio_stream\u001b[39m.\u001b[39;49mread(size, exception_on_overflow\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\gupta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyaudio.py:612\u001b[0m, in \u001b[0;36mStream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    608\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_input:\n\u001b[0;32m    609\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNot input stream\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    610\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 612\u001b[0m \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39;49mread_stream(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream, num_frames, exception_on_overflow)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ask_ques()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7415c622a2cd246d9a92e746407d19c15b5ff6770056ccf0aa12df4b72d3bf6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
